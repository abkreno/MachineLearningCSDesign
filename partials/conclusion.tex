As we have seen, Machine Learning can be applied successfully in the field of Algorithm Selection for modeling and training a classifier that is able to solve complex problems in constraints programming. We have shown how the training should be done by illustrating the modeling of the problem instance and the computing the features to be able to train the classifier.
\\\\
But in order to achieve good results. We discussed many important factors that has to be considered. Such as, computing a relatively small amount of features to avoid high penalty, caused by calculating expensive features, and at the same time making sure that the right features are calculated to cover a wide range of possible factors due to the fact that similar instances are likely to behave similarly.
\\\\
We also discussed the idea of using the common technique of duplicating the instances that was used for training.
This was done in order to push the classifiers towards learning more about the high cost instances, and to make sure that the important instances appear in the data more times than less important ones. Considering this factor affected the performance positively and reduced the misclassification penalty.
\\\\
The performance of the meta-classifier have shown an overall significant improvement over the default choice, and is able to make the correct decisions that will achieve better performance results and less penalty than using a default choice model designed by a human. The meta-classifier also as shown, is almost as good as the best classifier and much better than the worst classifier. We can conclude that with these results we have a strong evidence for the general applicability of a set of classifiers learned on a training set to sets of new, unknown instances\cite{ml:csd}.
